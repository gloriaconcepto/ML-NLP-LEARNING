{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHYuYnSVlXknA+VJ5NIsJA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gloriaconcepto/ML-NLP-LEARNING/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_14QvktwD4Sv"
      },
      "outputs": [],
      "source": [
        "s1 = 'Apple is looking at buying U.K. startup for $1 billion !'\n",
        "s2 = 'Hello all, We are here to help you! email support@udemy.com or visit us at http://www.udemy.com!'\n",
        "s3 = '10km cab ride almost costs $20 in NYC'\n",
        "s4 = \"Let's watch a movie together.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "KBgt0QgZFZYP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "axNFGqD4F2Zp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document1=nlp(s1)\n"
      ],
      "metadata": {
        "id": "rZGzeJaHGm73"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(document1)\n",
        "for token in document1:\n",
        "   print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2yqJLEvHSyY",
        "outputId": "fe43f773-a09e-42b1-b049-c1d1ebc7abfa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple is looking at buying U.K. startup for $1 billion !\n",
            "Apple\n",
            "is\n",
            "looking\n",
            "at\n",
            "buying\n",
            "U.K.\n",
            "startup\n",
            "for\n",
            "$\n",
            "1\n",
            "billion\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 = nlp(s2)\n",
        "print(s2)\n",
        "for token in doc2:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SkwrkYPHxMd",
        "outputId": "f51fe4a2-7f3e-4af7-9c8c-c008a8657462"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello all, We are here to help you! email support@udemy.com or visit us at http://www.udemy.com!\n",
            "Hello\n",
            "all\n",
            ",\n",
            "We\n",
            "are\n",
            "here\n",
            "to\n",
            "help\n",
            "you\n",
            "!\n",
            "email\n",
            "support@udemy.com\n",
            "or\n",
            "visit\n",
            "us\n",
            "at\n",
            "http://www.udemy.com\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Stemming and Lemmatization`"
      ],
      "metadata": {
        "id": "yzonvXnYKhvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "47GWgkKYKpRQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['run','runner','running','ran','runs','easily','fairly']"
      ],
      "metadata": {
        "id": "ZVY7X-XyLrxE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import  SnowballStemmer"
      ],
      "metadata": {
        "id": "IoJjU5FrLFy3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_stemmer = PorterStemmer()\n",
        "s_stemmer = SnowballStemmer(language='english')"
      ],
      "metadata": {
        "id": "OZynr4Z8Lw3K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + ' ------  ' +p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2wsx_j7ME2I",
        "outputId": "8447e870-ae1d-48f0-ad44-6a47ddb14970"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run ------  run\n",
            "runner ------  runner\n",
            "running ------  run\n",
            "ran ------  ran\n",
            "runs ------  run\n",
            "easily ------  easili\n",
            "fairly ------  fairli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + ' ------  ' +s_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vciHST19MMcy",
        "outputId": "df2d9659-0441-4033-992a-310b18525ee5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run ------  run\n",
            "runner ------  runner\n",
            "running ------  run\n",
            "ran ------  ran\n",
            "runs ------  run\n",
            "easily ------  easili\n",
            "fairly ------  fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization"
      ],
      "metadata": {
        "id": "sq_zv0SPMV56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(\"The striped bats are hanging on their feet for best\")"
      ],
      "metadata": {
        "id": "_Q_tKn8bMZSV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc1:\n",
        "  print(token.text, '\\t', token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPBYJqudObBS",
        "outputId": "931fe720-c43a-4c6d-cc6b-27998be2850c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The \t the\n",
            "striped \t stripe\n",
            "bats \t bat\n",
            "are \t be\n",
            "hanging \t hang\n",
            "on \t on\n",
            "their \t their\n",
            "feet \t foot\n",
            "for \t for\n",
            "best \t good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Rule-Based Matching\n"
      ],
      "metadata": {
        "id": "OtsUE5K68iQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Matcher library\n",
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab) # created matcher object and pass nlp.vocab"
      ],
      "metadata": {
        "id": "cXdLW2L-83e8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern_1 = [{'LOWER': 'hello'}, {'LOWER': 'world'}]\n",
        "pattern_2 = [{'LOWER': 'hello'}, {'IS_PUNCT': True}, {'LOWER': 'world'}]"
      ],
      "metadata": {
        "id": "RgbmaCw1918T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher.add('Hello World',[pattern_1, pattern_2])"
      ],
      "metadata": {
        "id": "Inqw7HoA-IAb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a document\n",
        "doc = nlp(\" 'Hello World' are the first two printed words for most of the programmers, printing 'Hello-World' is most common for beginners\")\n"
      ],
      "metadata": {
        "id": "9I12XtiEBAEv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_matches = matcher(doc) # passin doc to matcher object and store this in a variable\n",
        "print(find_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAHU34T5Bgfd",
        "outputId": "4752f3d3-a649-4c63-84da-d83042840e90"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(8585552006568828647, 2, 4), (8585552006568828647, 19, 22)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eFxCtYcuBmCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Xz0U2hl1Nv",
        "outputId": "29216de1-717e-4df3-aab7-67a9a9afb9d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# define a function to find the matches\n",
        "\n",
        "for match_id, start, end in find_matches:\n",
        "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
        "    span = doc[start:end]                    # get the matched span\n",
        "    print(match_id, string_id, start, end, span.text)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8585552006568828647 Hello World 2 4 Hello World\n",
            "8585552006568828647 Hello World 19 22 Hello-World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Phrase Matching"
      ],
      "metadata": {
        "id": "I-7DesDpB3EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "matcher_phrase = PhraseMatcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "rHOat-0PB668"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_list = [\"Barack Obama\", \"Angela Merkel\", \"Washington, D.C.\"]"
      ],
      "metadata": {
        "id": "rkZu2u3LDVgk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert each phrase to a document object\n",
        "phrase_patterns = [nlp(text) for text in phrase_list] # to do that we are using list comprehension"
      ],
      "metadata": {
        "id": "q-Drtz6XDaBX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass each doc object into the matcher\n",
        "matcher_phrase.add(\"TerminologyList\", None, *phrase_patterns)"
      ],
      "metadata": {
        "id": "o38ZMOJDDe2b"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_3 = nlp(\"German Chancellor Angela Merkel and US President Barack Obama \"\n",
        "          \"converse in the Oval Office inside the White House in Washington, D.C.\")"
      ],
      "metadata": {
        "id": "o2AyuGgiD53Z"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to find the matches\n",
        "\n",
        "for match_id, start, end in find_matches:\n",
        "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
        "    span = doc_3[start:end]                    # get the matched span\n",
        "    print(match_id, string_id, start, end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WappmFDFEC7A",
        "outputId": "4f35215b-d789-42ab-b8ef-2c289c37ab9b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8585552006568828647 Hello World 2 4 Angela Merkel\n",
            "8585552006568828647 Hello World 19 22 Washington, D.C.\n"
          ]
        }
      ]
    }
  ]
}